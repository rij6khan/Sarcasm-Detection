{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2eb2714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (0.17.2)\n",
      "Requirement already satisfied: sympy in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: numpy in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/xunuo/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc0f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  states slow to shut down weak teacher educatio...      0\n",
      "1    drone places fresh kill on steps of white house      1\n",
      "2  report: majority of instances of people gettin...      1\n",
      "3  sole remaining lung filled with rich, satisfyi...      1\n",
      "4                       the gop's stockholm syndrome      0\n",
      "0    11248\n",
      "1    10216\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "valid_df = pd.read_csv(\"valid.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e42cbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 20002\n"
     ]
    }
   ],
   "source": [
    "# 用 CountVectorizer 拿词表（只在 train 上 fit）\n",
    "max_features = 20000  # 词表上限，可以调大\n",
    "vectorizer = CountVectorizer(max_features=max_features, analyzer=\"word\")\n",
    "vectorizer.fit(train_df[\"text\"])\n",
    "\n",
    "# 建 word2idx 字典\n",
    "word2idx = {word: idx + 2 for idx, word in enumerate(vectorizer.get_feature_names_out())}\n",
    "word2idx[\"<pad>\"] = 0\n",
    "word2idx[\"<unk>\"] = 1\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "print(\"vocab_size =\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fceb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40  # headline 很短，40 足够\n",
    "\n",
    "def encode(sentence):\n",
    "    # 按空格切词\n",
    "    tokens = sentence.lower().split()\n",
    "    ids = [word2idx.get(w, word2idx[\"<unk>\"]) for w in tokens]\n",
    "    \n",
    "    if len(ids) > max_len:\n",
    "        ids = ids[:max_len]\n",
    "    else:\n",
    "        ids += [word2idx[\"<pad>\"]] * (max_len - len(ids))\n",
    "    \n",
    "    return torch.tensor(ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c9bebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21464, 40]) torch.Size([21464])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.stack([encode(t) for t in train_df[\"text\"]])\n",
    "X_valid = torch.stack([encode(t) for t in valid_df[\"text\"]])\n",
    "X_test  = torch.stack([encode(t) for t in test_df[\"text\"]])\n",
    "\n",
    "y_train = torch.tensor(train_df[\"label\"].values, dtype=torch.long)\n",
    "y_valid = torch.tensor(valid_df[\"label\"].values, dtype=torch.long)\n",
    "y_test  = torch.tensor(test_df[\"label\"].values, dtype=torch.long)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d76a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "valid_ds = TensorDataset(X_valid, y_valid)\n",
    "test_ds  = TensorDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1ffc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            outputs = model(X_batch)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            \n",
    "            preds.extend(pred.tolist())\n",
    "            labels.extend(y_batch.tolist())\n",
    "            \n",
    "            correct += (pred == y_batch).sum().item()\n",
    "            total += len(y_batch)\n",
    "    \n",
    "    acc = correct / total\n",
    "    return preds, labels, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960010f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 2)  # 二分类输出 2 维 logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, max_len)\n",
    "        x = self.embedding(x)        # (batch, max_len, embed_dim)\n",
    "        _, (h, _) = self.lstm(x)     # h: (num_layers*2, batch, hidden_dim)\n",
    "        # 取双向最后一层的两个方向的 hidden\n",
    "        h_fwd = h[-2]                # (batch, hidden_dim)\n",
    "        h_bwd = h[-1]                # (batch, hidden_dim)\n",
    "        out = torch.cat([h_fwd, h_bwd], dim=1)  # (batch, 2*hidden_dim)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)           # (batch, 2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db69bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMClassifier(vocab_size=vocab_size, embed_dim=100, hidden_dim=64)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "784faad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1/10, train_loss=182.140, val_acc=0.7989\n",
      "[LSTM] Epoch 2/10, train_loss=134.067, val_acc=0.8128\n",
      "[LSTM] Epoch 3/10, train_loss=102.290, val_acc=0.8017\n",
      "[LSTM] Epoch 4/10, train_loss=76.218, val_acc=0.8142\n",
      "[LSTM] Epoch 5/10, train_loss=54.926, val_acc=0.8059\n",
      "[LSTM] Epoch 6/10, train_loss=37.380, val_acc=0.8184\n",
      "[LSTM] Epoch 7/10, train_loss=25.476, val_acc=0.8073\n",
      "[LSTM] Epoch 8/10, train_loss=17.038, val_acc=0.7975\n",
      "Early stopping triggered for LSTM!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "patience = 2\n",
    "wait = 0\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = lstm_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # 每个 epoch 后在 valid 上评估\n",
    "    preds, labels, val_acc = evaluate(lstm_model, valid_loader)\n",
    "    print(f\"[LSTM] Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"train_loss={epoch_loss:.3f}, val_acc={val_acc:.4f}\")\n",
    "    \n",
    "    # early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_lstm_state = lstm_model.state_dict()\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered for LSTM!\")\n",
    "            break\n",
    "\n",
    "# 加载验证集上表现最好的参数\n",
    "lstm_model.load_state_dict(best_lstm_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6e5eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM on VALID:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       360\n",
      "           1       0.81      0.77      0.79       356\n",
      "\n",
      "    accuracy                           0.80       716\n",
      "   macro avg       0.80      0.80      0.80       716\n",
      "weighted avg       0.80      0.80      0.80       716\n",
      "\n",
      "[[296  64]\n",
      " [ 81 275]]\n",
      "LSTM on TEST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       526\n",
      "           1       0.80      0.74      0.77       440\n",
      "\n",
      "    accuracy                           0.80       966\n",
      "   macro avg       0.80      0.80      0.80       966\n",
      "weighted avg       0.80      0.80      0.80       966\n",
      "\n",
      "[[446  80]\n",
      " [113 327]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# VALID\n",
    "preds_valid_lstm, labels_valid_lstm, val_acc_lstm = evaluate(lstm_model, valid_loader)\n",
    "print(\"LSTM on VALID:\")\n",
    "print(classification_report(labels_valid_lstm, preds_valid_lstm))\n",
    "print(confusion_matrix(labels_valid_lstm, preds_valid_lstm))\n",
    "\n",
    "# TEST\n",
    "preds_test_lstm, labels_test_lstm, test_acc_lstm = evaluate(lstm_model, test_loader)\n",
    "print(\"LSTM on TEST:\")\n",
    "print(classification_report(labels_test_lstm, preds_test_lstm))\n",
    "print(confusion_matrix(labels_test_lstm, preds_test_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad6895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602607e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30e07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
